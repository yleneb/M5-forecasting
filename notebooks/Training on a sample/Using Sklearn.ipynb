{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = pathlib.Path().absolute().parent.parent\n",
    "RAW_DATA_PATH = ROOT / 'data' / 'raw'\n",
    "INTERIM_DATA_PATH = ROOT / 'data' / 'interim'\n",
    "PROCESSED_DATA_PATH = ROOT / 'data' / 'processed'\n",
    "DAYS_PRED = 28\n",
    "\n",
    "# endure this project is in the path\n",
    "sys.path.insert(0, ROOT.absolute().as_posix())\n",
    "from src.data.process_data import reduce_memory_usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will work with just one department in one store\n",
    "df = \\\n",
    "(pd\n",
    " .read_parquet(PROCESSED_DATA_PATH / 'train_validation' /'FOODS_3_CA_1.parquet')\n",
    " .pipe(reduce_memory_usage)\n",
    " .astype({c:'category' for c in ['wday','month','year']})\n",
    " .drop(columns=['id','dept_id','cat_id','store_id',\n",
    "                'state_id','date','wday','d']))\n",
    "\n",
    "# get rid of categories from aother parts of the dataset\n",
    "for col, dtype in zip(df.columns, df.dtypes):\n",
    "    if str(dtype) == 'category':\n",
    "        df[col] = df[col].cat.remove_unused_categories()\n",
    "\n",
    "# I want to undo get_dummies on event_names and event_types\n",
    "# for simplicity only consider the first event if there is more than 1\n",
    "event_name = \\\n",
    "(df\n",
    " .filter(like='event_name_')\n",
    " .assign(event_name_none=lambda df: ~df.any(axis=1))\n",
    " .stack()\n",
    " .reset_index()\n",
    " .rename(columns={'level_0':'index','level_1':'event_name',0:'is_event'})\n",
    " .query(\"\"\"is_event == True\"\"\")\n",
    " .groupby('index', as_index=True)\n",
    " .first()\n",
    " .drop(columns=['is_event']))\n",
    "\n",
    "event_type = \\\n",
    "(df\n",
    " .filter(like='event_type_')\n",
    " .assign(event_type_none=lambda df: ~df.any(axis=1))\n",
    " .stack()\n",
    " .reset_index()\n",
    " .rename(columns={'level_0':'index','level_1':'event_type',0:'is_event'})\n",
    " .query(\"\"\"is_event == True\"\"\")\n",
    " .groupby('index', as_index=True)\n",
    " .first()\n",
    " .drop(columns=['is_event']))\n",
    "\n",
    "# join in these 'un-dummied' features and drop the dummies\n",
    "df = \\\n",
    "(df\n",
    " .join(event_type)\n",
    " .join(event_name)\n",
    " .filter(regex=r'^((?!event_name_).)*$')\n",
    " .filter(regex=r'^((?!event_type_).)*$')\n",
    "#  .replace(\n",
    "#      {'event_type':{'event_type_none':'none'},\n",
    "#       'event_name':{'event_name_none':'none'}})\n",
    " .astype({c:'category' for c in ['event_type','event_name',\n",
    "                                 'quarter','weekofyear',\n",
    "                                 'day','dayofyear']}))\n",
    "\n",
    "# separate out a test set\n",
    "train = df[df.part=='train'].drop(columns=['part'])\n",
    "train_labels = train.pop('demand')\n",
    "\n",
    "test = df[df.part=='validation'].drop(columns=['part'])\n",
    "test_labels = test.pop('demand')\n",
    "del df, event_name, event_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1257138 entries, 0 to 1280153\n",
      "Data columns (total 44 columns):\n",
      " #   Column                           Non-Null Count    Dtype   \n",
      "---  ------                           --------------    -----   \n",
      " 0   item_id                          1257138 non-null  category\n",
      " 1   weekday                          1257138 non-null  category\n",
      " 2   month                            1257138 non-null  category\n",
      " 3   year                             1257138 non-null  category\n",
      " 4   is_weekend                       1257138 non-null  bool    \n",
      " 5   event                            1257138 non-null  bool    \n",
      " 6   snap                             1257138 non-null  bool    \n",
      " 7   sell_price_cent                  1257138 non-null  uint16  \n",
      " 8   shift_t28                        1257138 non-null  uint16  \n",
      " 9   shift_t29                        1257138 non-null  uint16  \n",
      " 10  shift_t30                        1257138 non-null  uint16  \n",
      " 11  rolling_std_t7                   1257138 non-null  float16 \n",
      " 12  rolling_std_t30                  1257138 non-null  float16 \n",
      " 13  rolling_std_t60                  1257138 non-null  float16 \n",
      " 14  rolling_std_t90                  1257138 non-null  float16 \n",
      " 15  rolling_std_t180                 1257138 non-null  float16 \n",
      " 16  rolling_mean_t7                  1257138 non-null  float16 \n",
      " 17  rolling_mean_t30                 1257138 non-null  float16 \n",
      " 18  rolling_mean_t60                 1257138 non-null  float16 \n",
      " 19  rolling_mean_t90                 1257138 non-null  float16 \n",
      " 20  rolling_mean_t180                1257138 non-null  float16 \n",
      " 21  rolling_skew_t30                 1257138 non-null  float16 \n",
      " 22  rolling_kurt_t30                 1257138 non-null  float16 \n",
      " 23  rolling_nonzero_sale_count_t7    1257138 non-null  uint8   \n",
      " 24  rolling_nonzero_sale_count_t30   1257138 non-null  uint8   \n",
      " 25  rolling_nonzero_sale_count_t60   1257138 non-null  uint8   \n",
      " 26  rolling_nonzero_sale_count_t90   1257138 non-null  uint8   \n",
      " 27  rolling_nonzero_sale_count_t180  1257138 non-null  uint8   \n",
      " 28  price_change_t1                  1257138 non-null  float16 \n",
      " 29  price_change_t365                1257138 non-null  float16 \n",
      " 30  rolling_price_std_t7             1257138 non-null  float16 \n",
      " 31  rolling_price_std_t30            1257138 non-null  float16 \n",
      " 32  quarter                          1257138 non-null  category\n",
      " 33  weekofyear                       1257138 non-null  category\n",
      " 34  day                              1257138 non-null  category\n",
      " 35  dayofyear                        1257138 non-null  category\n",
      " 36  is_year_end                      1257138 non-null  bool    \n",
      " 37  is_year_start                    1257138 non-null  bool    \n",
      " 38  is_quarter_end                   1257138 non-null  bool    \n",
      " 39  is_quarter_start                 1257138 non-null  bool    \n",
      " 40  is_month_end                     1257138 non-null  bool    \n",
      " 41  is_month_start                   1257138 non-null  bool    \n",
      " 42  event_type                       1257138 non-null  category\n",
      " 43  event_name                       1257138 non-null  category\n",
      "dtypes: bool(9), category(10), float16(16), uint16(4), uint8(5)\n",
      "memory usage: 88.8 MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "event_type\n",
       "event_type_cultural       24680\n",
       "event_type_national       33819\n",
       "event_type_none         1156336\n",
       "event_type_religious      32820\n",
       "event_type_sporting        9483\n",
       "dtype: int64"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby('event_type').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "# select features\n",
    "to_drop = ['day','weekofyear','dayofyear','item_id','quarter']\n",
    "\n",
    "num_attribs = [col for col, dtype in zip(train.columns, train.dtypes)\n",
    "               if ('float' in str(dtype) or 'int' in str(dtype))\n",
    "               and col not in to_drop]\n",
    "\n",
    "cat_attribs = [col for col, dtype in zip(train.columns, train.dtypes)\n",
    "               if str(dtype)=='category'\n",
    "               and col not in to_drop]\n",
    "\n",
    "# define pipelines\n",
    "num_pipeline = Pipeline([\n",
    "    ('std_scalar', StandardScaler())])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    ('one_hot_enc', OneHotEncoder())])\n",
    "\n",
    "# combine pipelines\n",
    "full_pipeline = ColumnTransformer([\n",
    "    ('num', num_pipeline, num_attribs),\n",
    "    ('cat', cat_pipeline, cat_attribs),\n",
    "    ('drop', 'drop', to_drop)],\n",
    "    remainder='passthrough')\n",
    "\n",
    "train_prepared = full_pipeline.fit_transform(train, train_labels)\n",
    "test_prepared = full_pipeline.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 4.76, NNZs: 95, Bias: 1.276247, T: 1257138, Avg. loss: 13.818281\n",
      "Total training time: 0.75 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 4.87, NNZs: 95, Bias: 1.318003, T: 2514276, Avg. loss: 12.218457\n",
      "Total training time: 1.49 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 4.99, NNZs: 95, Bias: 1.385635, T: 3771414, Avg. loss: 11.965164\n",
      "Total training time: 2.24 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 4.49, NNZs: 95, Bias: 1.470842, T: 5028552, Avg. loss: 11.995972\n",
      "Total training time: 2.98 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 4.85, NNZs: 95, Bias: 1.378741, T: 6285690, Avg. loss: 11.863051\n",
      "Total training time: 3.73 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 4.88, NNZs: 95, Bias: 1.429363, T: 7542828, Avg. loss: 11.714852\n",
      "Total training time: 4.48 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 4.90, NNZs: 95, Bias: 1.405134, T: 8799966, Avg. loss: 11.709570\n",
      "Total training time: 5.22 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 4.85, NNZs: 95, Bias: 1.400551, T: 10057104, Avg. loss: 11.666442\n",
      "Total training time: 5.97 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 5.01, NNZs: 95, Bias: 1.469039, T: 11314242, Avg. loss: 11.553011\n",
      "Total training time: 6.72 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 5.02, NNZs: 95, Bias: 1.447457, T: 12571380, Avg. loss: 11.581196\n",
      "Total training time: 7.47 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 5.19, NNZs: 95, Bias: 1.484095, T: 13828518, Avg. loss: 11.614805\n",
      "Total training time: 8.22 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 4.92, NNZs: 95, Bias: 1.486604, T: 15085656, Avg. loss: 11.507345\n",
      "Total training time: 8.97 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 5.26, NNZs: 95, Bias: 1.588444, T: 16342794, Avg. loss: 11.581347\n",
      "Total training time: 9.72 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 4.91, NNZs: 95, Bias: 1.479024, T: 17599932, Avg. loss: 11.507642\n",
      "Total training time: 10.47 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 4.52, NNZs: 95, Bias: 1.526231, T: 18857070, Avg. loss: 11.466643\n",
      "Total training time: 11.21 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 4.90, NNZs: 95, Bias: 1.544813, T: 20114208, Avg. loss: 11.594398\n",
      "Total training time: 11.96 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 5.34, NNZs: 95, Bias: 1.591512, T: 21371346, Avg. loss: 11.563716\n",
      "Total training time: 12.71 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 4.95, NNZs: 95, Bias: 1.606096, T: 22628484, Avg. loss: 11.487444\n",
      "Total training time: 13.46 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 4.88, NNZs: 95, Bias: 1.526293, T: 23885622, Avg. loss: 11.463022\n",
      "Total training time: 14.20 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 4.76, NNZs: 95, Bias: 1.567007, T: 25142760, Avg. loss: 11.442156\n",
      "Total training time: 14.95 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 4.86, NNZs: 95, Bias: 1.588831, T: 26399898, Avg. loss: 11.425707\n",
      "Total training time: 15.70 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 5.00, NNZs: 95, Bias: 1.605888, T: 27657036, Avg. loss: 11.455484\n",
      "Total training time: 16.45 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 4.60, NNZs: 95, Bias: 1.600394, T: 28914174, Avg. loss: 11.459082\n",
      "Total training time: 17.20 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 5.20, NNZs: 95, Bias: 1.635073, T: 30171312, Avg. loss: 11.428000\n",
      "Total training time: 17.94 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 4.78, NNZs: 95, Bias: 1.609150, T: 31428450, Avg. loss: 11.334264\n",
      "Total training time: 18.70 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 4.66, NNZs: 95, Bias: 1.609024, T: 32685588, Avg. loss: 11.412882\n",
      "Total training time: 19.45 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 4.70, NNZs: 95, Bias: 1.629104, T: 33942726, Avg. loss: 11.397567\n",
      "Total training time: 20.20 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 4.99, NNZs: 95, Bias: 1.647155, T: 35199864, Avg. loss: 11.427444\n",
      "Total training time: 20.95 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 4.73, NNZs: 95, Bias: 1.711121, T: 36457002, Avg. loss: 11.416284\n",
      "Total training time: 21.70 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 4.75, NNZs: 95, Bias: 1.684795, T: 37714140, Avg. loss: 11.426857\n",
      "Total training time: 22.45 seconds.\n",
      "Convergence after 30 epochs took 22.45 seconds\n",
      "train rmse: 4.658716017427967\n",
      "train rmse: 4.8729731315098705\n"
     ]
    }
   ],
   "source": [
    "# try permutation importance as an alternative of feature importance\n",
    "\n",
    "# I need to split out a validation set for CV\n",
    "# need to set up GridSearch for a selection of models and hyperparams\n",
    "# the grid search should include feature selection\n",
    "\n",
    "# experiment witrh XGBoost, CatBoost, LightGBM\n",
    "\n",
    "# package all this into a class for more convenient training\n",
    "# when a good model is chosen using CV train on the full dataset and predict\n",
    "\n",
    "# for completion, build backwards so I start with the raw data\n",
    "\n",
    "# finally, recreate using dask, then GPU\n",
    "\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# fit\n",
    "m = SGDRegressor(random_state=42, verbose=1)\n",
    "m.fit(train_prepared, train_labels)\n",
    "\n",
    "# scores\n",
    "train_preds = m.predict(train_prepared)\n",
    "mse = mean_squared_error(train_labels, m.predict(train_prepared))\n",
    "print(f'train rmse: {mse**0.5}')\n",
    "\n",
    "test_preds = m.predict(test_prepared)\n",
    "mse = mean_squared_error(test_labels, m.predict(test_prepared))\n",
    "print(f'test rmse: {mse**0.5}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "import plotly.express as px\n",
    "\n",
    "result = permutation_importance(\n",
    "    m, train_prepared, train_labels, n_repeats=5,\n",
    "    random_state=42, n_jobs=-1)\n",
    "\n",
    "# sorted_idx = result.importances_mean.argsort()\n",
    "result.importances_mean.sort()\n",
    "# to_plot = pd.DataFrame(\n",
    "#     result.importances[sorted_idx].T,\n",
    "# #     columns=test.columns[sorted_idx]\n",
    "# ).melt()\n",
    "\n",
    "# px.box(to_plot, y='value', color='variable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-9.95512861e-05, -8.26393101e-07, -2.46331754e-07, -1.44200609e-07,\n",
       "       -4.26519501e-08, -2.44073391e-08, -1.79787167e-08,  1.57038993e-09,\n",
       "        3.43931643e-08,  4.37970619e-08,  2.64177412e-07,  4.78101706e-07,\n",
       "        4.80736763e-07,  7.93511370e-07,  8.17189930e-07,  1.11375458e-06,\n",
       "        1.14608368e-06,  1.43053383e-06,  1.69891973e-06,  1.93078520e-06,\n",
       "        2.13799012e-06,  2.16312937e-06,  2.85643631e-06,  3.37419511e-06,\n",
       "        3.69594740e-06,  4.87860717e-06,  5.11642148e-06,  6.97536753e-06,\n",
       "        7.06619659e-06,  7.86721484e-06,  8.64868904e-06,  8.77004068e-06,\n",
       "        8.95686502e-06,  8.98378367e-06,  1.04406825e-05,  1.18264714e-05,\n",
       "        1.56378462e-05,  1.57169063e-05,  1.58189364e-05,  1.68894597e-05,\n",
       "        1.89793775e-05,  1.89793775e-05,  2.07666939e-05,  2.54774114e-05,\n",
       "        3.09247891e-05,  3.15750376e-05,  3.30662231e-05,  3.38298823e-05,\n",
       "        3.79562110e-05,  5.11035417e-05,  5.64881785e-05,  5.71239552e-05,\n",
       "        6.65541103e-05,  6.91746348e-05,  7.54533255e-05,  7.97969816e-05,\n",
       "        8.32248261e-05,  8.81057929e-05,  1.00451291e-04,  1.33314036e-04,\n",
       "        1.45615896e-04,  1.45799998e-04,  1.53581877e-04,  1.56533733e-04,\n",
       "        1.72436535e-04,  2.10022657e-04,  2.17228907e-04,  2.59448183e-04,\n",
       "        2.83132314e-04,  3.76054990e-04,  3.89002430e-04,  4.52445074e-04,\n",
       "        4.63923231e-04,  5.47138087e-04,  5.47138087e-04,  5.69192854e-04,\n",
       "        5.77645734e-04,  6.12513169e-04,  6.34719049e-04,  7.57979102e-04,\n",
       "        7.86254579e-04,  1.26409466e-03,  1.64139850e-03,  3.40957121e-03,\n",
       "        3.75140628e-03,  3.85715211e-03,  5.15606968e-03,  5.25509014e-03,\n",
       "        1.09975618e-02,  1.49910948e-02,  1.62681711e-02,  3.56665844e-02,\n",
       "        6.51149778e-02,  8.26361219e-02,  1.80744214e-01])"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.importances_mean"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:M5-forecasting] *",
   "language": "python",
   "name": "conda-env-M5-forecasting-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
